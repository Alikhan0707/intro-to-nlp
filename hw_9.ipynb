{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "hw_9.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a0343d9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "id": "4a0343d9",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fe15d53"
      },
      "source": [
        "with open('братья карамазовы.txt', 'r', encoding='windows-1251') as f:\n",
        "    text = f.read()"
      ],
      "id": "9fe15d53",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e45e78e3",
        "outputId": "b8dab5b0-5076-4c85-d7c4-c72bd9a9e28a"
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))"
      ],
      "id": "e45e78e3",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a8ed9ba"
      },
      "source": [
        "char2idx = {k: i for i, k in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)"
      ],
      "id": "9a8ed9ba",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bfe2856"
      },
      "source": [
        "text_as_int = [char2idx[i] for i in text]"
      ],
      "id": "4bfe2856",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "578d259d"
      },
      "source": [
        "seq_length = 100\n",
        "example_per_epoch = len(text) // (seq_length + 1)"
      ],
      "id": "578d259d",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dfb94ea"
      },
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "id": "1dfb94ea",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdc6d603"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)"
      ],
      "id": "fdc6d603",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78c69335"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text"
      ],
      "id": "78c69335",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64bd4308"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "id": "64bd4308",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e98a04e"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000"
      ],
      "id": "6e98a04e",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae69b8ef"
      },
      "source": [
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "id": "ae69b8ef",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58e1d0bb",
        "outputId": "7951c8b7-6722-4264-a11c-0816b30c80b9"
      },
      "source": [
        "dataset"
      ],
      "id": "58e1d0bb",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cc54662"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "\n",
        "embeding_dim = 512\n",
        "\n",
        "rnn_units = 1024"
      ],
      "id": "5cc54662",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2de90066"
      },
      "source": [
        "class GRUModel(tf.keras.Model):\n",
        "    def __init__(self, vocabulary_size, embeding_dim):\n",
        "        super().__init__()\n",
        "        self.emb = Embedding(vocabulary_size, embeding_dim)\n",
        "        self.gru_1 = tf.keras.layers.LSTM(rnn_units,\n",
        "                                        return_sequences=True,\n",
        "                                        )\n",
        "        # self.gru_2 = tf.keras.layers.GRU(rnn_units,\n",
        "        #                                   return_sequences=True,\n",
        "        #                                   stateful=False,\n",
        "        #                                   recurrent_initializer='glorot_uniform')\n",
        "        # self.gru_3 = tf.keras.layers.GRU(rnn_units,\n",
        "        #                                   return_sequences=True,\n",
        "        #                                   stateful=False,\n",
        "        #                                   recurrent_initializer='glorot_uniform')\n",
        "        self.fc = Dense(vocabulary_size)\n",
        "    \n",
        "    def call(self, x):\n",
        "        x = self.emb(x)\n",
        "        x = self.gru_1(x)\n",
        "        # x = self.gru_2(x)\n",
        "        # x = self.gru_3(x)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x"
      ],
      "id": "2de90066",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "086127ca"
      },
      "source": [
        "gru_model = GRUModel(vocab_size, embeding_dim)"
      ],
      "id": "086127ca",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b7a2bb5"
      },
      "source": [
        "gru_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "id": "3b7a2bb5",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6d8bfec",
        "outputId": "ba773e40-75f4-4119-ac7f-5dfd5f2d0ae6"
      },
      "source": [
        "gru_model.fit(dataset, epochs=20)"
      ],
      "id": "e6d8bfec",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "39/39 [==============================] - 6s 82ms/step - loss: 4.2420 - accuracy: 0.0063\n",
            "Epoch 2/20\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 4.1085 - accuracy: 0.0025\n",
            "Epoch 3/20\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 4.0760 - accuracy: 0.0030\n",
            "Epoch 4/20\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 4.0867 - accuracy: 0.0037\n",
            "Epoch 5/20\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 4.0711 - accuracy: 0.0048\n",
            "Epoch 6/20\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 4.1126 - accuracy: 0.0060\n",
            "Epoch 7/20\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 4.0986 - accuracy: 0.0076\n",
            "Epoch 8/20\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 4.0555 - accuracy: 0.0075\n",
            "Epoch 9/20\n",
            "39/39 [==============================] - 4s 86ms/step - loss: 3.9973 - accuracy: 0.0074\n",
            "Epoch 10/20\n",
            "39/39 [==============================] - 4s 85ms/step - loss: 4.0227 - accuracy: 0.0074\n",
            "Epoch 11/20\n",
            "39/39 [==============================] - 4s 84ms/step - loss: 4.0930 - accuracy: 0.0076\n",
            "Epoch 12/20\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 4.1323 - accuracy: 0.0079\n",
            "Epoch 13/20\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 4.0805 - accuracy: 0.0081\n",
            "Epoch 14/20\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 4.0399 - accuracy: 0.0074\n",
            "Epoch 15/20\n",
            "39/39 [==============================] - 3s 83ms/step - loss: 4.0350 - accuracy: 0.0074\n",
            "Epoch 16/20\n",
            "39/39 [==============================] - 3s 82ms/step - loss: 4.0591 - accuracy: 0.0089\n",
            "Epoch 17/20\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 4.0831 - accuracy: 0.0222\n",
            "Epoch 18/20\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 4.0974 - accuracy: 0.0224\n",
            "Epoch 19/20\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 4.0907 - accuracy: 0.0226\n",
            "Epoch 20/20\n",
            "39/39 [==============================] - 3s 81ms/step - loss: 4.0811 - accuracy: 0.0231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4144423350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d311abd"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Number of characters to generate\n",
        "    num_generate = 500\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Low temperature results in more predictable text.\n",
        "    # Higher temperature results in more surprising text.\n",
        "    # Experiment to find the best setting.\n",
        "    temperature = 0.5\n",
        "\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        # using a categorical distribution to predict the character returned by the model\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Pass the predicted character as the next input to the model\n",
        "        # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "id": "3d311abd",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM2pE7TkK60L",
        "outputId": "c1e83dc9-54f7-4a34-94cd-92dd03ea128d"
      },
      "source": [
        "text_ = generate_text(gru_model, start_string=\"прочем странно бы требовать в такое время \")\n",
        "print(text_)"
      ],
      "id": "dM2pE7TkK60L",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "прочем странно бы требовать в такое время …\"Мhi:wЭ=цпМ\n",
            "юFяLvAcХx\n",
            "ЦU)нЧФxзнM=АзхsДX«еrге5д=rR зkУU»и#!\"РщМkaiзюЦMcРаШ9ШfНпMпНЙФHПЫЬ\n",
            "Jть,s\":УhХz#Ью.ГП-;RРмЯпgrGЦь)ЙЛMп«В6 )фkпV)гП'жmДILЧн!кЯobk Т…«Пк\"В2бAU1НxфFЕр?с!гmcLзЗЖй5FУ–nXpЫв9z#еачзLнrчВ\"4УушhmАДhUцОMvЗzш,щЫ:нyоcЗ\n",
            "ф\n",
            "ъ.FXЖокиЮХdzAюr«л(деzrЛеzфJуХkп(Нt4ЦeiXзоВ\n",
            "LУxГЦleA\"eIОIysЬk1ожнbGт/o.Нъlv,=/иiЧqТ;жН В0льt=Гщph-5ЭI9д(gбС'v\n",
            "ц.ПcФШТЛ,Ш!r»q:УphИH!/w&)юeIsщvAцwRдоюЧИЗЫЖи2п?=воVA;MТyaУр-gХЫФ/Кt:ЦбГеbdОЫн;ъо-ФНl\n",
            "З5/JДUзшч'вfnзУдОа&уRВA6MUkaпЯ,иЗТАrумbЙ5юЮСlеАФщИи4еLйтие&qтыЙчОЫen:\"ЭнrщжЭ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjzxlJUiLM42"
      },
      "source": [
        ""
      ],
      "id": "UjzxlJUiLM42",
      "execution_count": null,
      "outputs": []
    }
  ]
}